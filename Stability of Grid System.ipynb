{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ce1a10",
   "metadata": {},
   "source": [
    "# Stability of Grid System\n",
    "\n",
    "Instructions for Tag-Along Project\n",
    "Stability of the Grid System\n",
    "\n",
    "Electrical grids require a balance between electricity supply and demand in order to be stable. Conventional systems achieve this balance through demand-driven electricity production. For future grids with a high share of inflexible (i.e., renewable) energy sources, the concept of demand response is a promising solution. This implies changes in electricity consumption in relation to electricity price changes. In this work, we’ll build a binary classification model to predict if a grid is stable or unstable using the UCI Electrical Grid Stability Simulated dataset.\n",
    "\n",
    "Dataset: https://archive.ics.uci.edu/ml/datasets/Electrical+Grid+Stability+Simulated+Data+\n",
    "\n",
    "It has 12 primary predictive features and two dependent variables.\n",
    "\n",
    "Predictive features:\n",
    "\n",
    "'tau1' to 'tau4': the reaction time of each network participant, a real value within the range 0.5 to 10 ('tau1' corresponds to the supplier node, 'tau2' to 'tau4' to the consumer nodes);\n",
    "'p1' to 'p4': nominal power produced (positive) or consumed (negative) by each network participant, a real value within the range -2.0 to -0.5 for consumers ('p2' to 'p4'). As the total power consumed equals the total power generated, p1 (supplier node) = - (p2 + p3 + p4);\n",
    "'g1' to 'g4': price elasticity coefficient for each network participant, a real value within the range 0.05 to 1.00 ('g1' corresponds to the supplier node, 'g2' to 'g4' to the consumer nodes; 'g' stands for 'gamma');\n",
    "Dependent variables:\n",
    "\n",
    "'stab': the maximum real part of the characteristic differential equation root (if positive, the system is linearly unstable; if negative, linearly stable);\n",
    "'stabf': a categorical (binary) label ('stable' or 'unstable').\n",
    "Because of the direct relationship between 'stab' and 'stabf' ('stabf' = 'stable' if 'stab' <= 0, 'unstable' otherwise), 'stab' should be dropped and 'stabf' will remain as the sole dependent variable (binary classification).\n",
    "\n",
    "Split the data into an 80-20 train-test split with a random state of “1”. Use the standard scaler to transform the train set (x_train, y_train) and the test set (x_test). Use scikit learn to train a random forest and extra trees classifier. And use xgboost and lightgbm to train an extreme boosting model and a light gradient boosting model. Use random_state = 1 for training all models and evaluate on the test set. Answer the following questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c476873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b62464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='https://archive.ics.uci.edu/ml/machine-learning-databases/00471/Data_for_UCI_named.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "491abc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "urlretrieve(url,'Hsd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "875353ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_41e55_row0_col0, #T_41e55_row4_col10 {\n",
       "  background-color: #cdd0e5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41e55_row0_col1, #T_41e55_row0_col7, #T_41e55_row1_col2, #T_41e55_row1_col5, #T_41e55_row1_col10, #T_41e55_row1_col12, #T_41e55_row2_col2, #T_41e55_row2_col3, #T_41e55_row2_col4, #T_41e55_row2_col8, #T_41e55_row2_col11, #T_41e55_row3_col0, #T_41e55_row3_col6, #T_41e55_row4_col9 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41e55_row0_col2, #T_41e55_row0_col5, #T_41e55_row0_col6, #T_41e55_row0_col11, #T_41e55_row0_col12, #T_41e55_row1_col0, #T_41e55_row1_col4, #T_41e55_row2_col1, #T_41e55_row3_col9, #T_41e55_row3_col10, #T_41e55_row4_col3, #T_41e55_row4_col7, #T_41e55_row4_col8 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41e55_row0_col3 {\n",
       "  background-color: #023a5b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41e55_row0_col4 {\n",
       "  background-color: #d8d7e9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41e55_row0_col8 {\n",
       "  background-color: #056dab;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41e55_row0_col9 {\n",
       "  background-color: #056ba9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41e55_row0_col10 {\n",
       "  background-color: #045788;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41e55_row1_col1 {\n",
       "  background-color: #bbc7e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41e55_row1_col3 {\n",
       "  background-color: #fdf5fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41e55_row1_col6 {\n",
       "  background-color: #f1ebf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41e55_row1_col7 {\n",
       "  background-color: #9cb9d9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41e55_row1_col8 {\n",
       "  background-color: #9ebad9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41e55_row1_col9 {\n",
       "  background-color: #056ba7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41e55_row1_col11 {\n",
       "  background-color: #0569a4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41e55_row2_col0 {\n",
       "  background-color: #034267;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41e55_row2_col5 {\n",
       "  background-color: #328dbf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41e55_row2_col6 {\n",
       "  background-color: #023f64;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41e55_row2_col7 {\n",
       "  background-color: #1e80b8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41e55_row2_col9 {\n",
       "  background-color: #4496c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41e55_row2_col10 {\n",
       "  background-color: #056fae;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41e55_row2_col12 {\n",
       "  background-color: #e6e2ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41e55_row3_col1 {\n",
       "  background-color: #0568a3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41e55_row3_col2 {\n",
       "  background-color: #c9cee4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41e55_row3_col3 {\n",
       "  background-color: #ebe6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41e55_row3_col4 {\n",
       "  background-color: #b3c3de;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41e55_row3_col5 {\n",
       "  background-color: #0569a5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41e55_row3_col7 {\n",
       "  background-color: #3991c1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41e55_row3_col8 {\n",
       "  background-color: #89b1d4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41e55_row3_col11 {\n",
       "  background-color: #c0c9e2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41e55_row3_col12 {\n",
       "  background-color: #529bc7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41e55_row4_col0 {\n",
       "  background-color: #c5cce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41e55_row4_col1 {\n",
       "  background-color: #056aa6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41e55_row4_col2 {\n",
       "  background-color: #acc0dd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41e55_row4_col4 {\n",
       "  background-color: #f4eef6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41e55_row4_col5 {\n",
       "  background-color: #167bb6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41e55_row4_col6 {\n",
       "  background-color: #eae6f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_41e55_row4_col11 {\n",
       "  background-color: #046097;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_41e55_row4_col12 {\n",
       "  background-color: #034f7d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_41e55_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >tau1</th>\n",
       "      <th class=\"col_heading level0 col1\" >tau2</th>\n",
       "      <th class=\"col_heading level0 col2\" >tau3</th>\n",
       "      <th class=\"col_heading level0 col3\" >tau4</th>\n",
       "      <th class=\"col_heading level0 col4\" >p1</th>\n",
       "      <th class=\"col_heading level0 col5\" >p2</th>\n",
       "      <th class=\"col_heading level0 col6\" >p3</th>\n",
       "      <th class=\"col_heading level0 col7\" >p4</th>\n",
       "      <th class=\"col_heading level0 col8\" >g1</th>\n",
       "      <th class=\"col_heading level0 col9\" >g2</th>\n",
       "      <th class=\"col_heading level0 col10\" >g3</th>\n",
       "      <th class=\"col_heading level0 col11\" >g4</th>\n",
       "      <th class=\"col_heading level0 col12\" >stab</th>\n",
       "      <th class=\"col_heading level0 col13\" >stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_41e55_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_41e55_row0_col0\" class=\"data row0 col0\" >2.959060</td>\n",
       "      <td id=\"T_41e55_row0_col1\" class=\"data row0 col1\" >3.079885</td>\n",
       "      <td id=\"T_41e55_row0_col2\" class=\"data row0 col2\" >8.381025</td>\n",
       "      <td id=\"T_41e55_row0_col3\" class=\"data row0 col3\" >9.780754</td>\n",
       "      <td id=\"T_41e55_row0_col4\" class=\"data row0 col4\" >3.763085</td>\n",
       "      <td id=\"T_41e55_row0_col5\" class=\"data row0 col5\" >-0.782604</td>\n",
       "      <td id=\"T_41e55_row0_col6\" class=\"data row0 col6\" >-1.257395</td>\n",
       "      <td id=\"T_41e55_row0_col7\" class=\"data row0 col7\" >-1.723086</td>\n",
       "      <td id=\"T_41e55_row0_col8\" class=\"data row0 col8\" >0.650456</td>\n",
       "      <td id=\"T_41e55_row0_col9\" class=\"data row0 col9\" >0.859578</td>\n",
       "      <td id=\"T_41e55_row0_col10\" class=\"data row0 col10\" >0.887445</td>\n",
       "      <td id=\"T_41e55_row0_col11\" class=\"data row0 col11\" >0.958034</td>\n",
       "      <td id=\"T_41e55_row0_col12\" class=\"data row0 col12\" >0.055347</td>\n",
       "      <td id=\"T_41e55_row0_col13\" class=\"data row0 col13\" >unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41e55_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_41e55_row1_col0\" class=\"data row1 col0\" >9.304097</td>\n",
       "      <td id=\"T_41e55_row1_col1\" class=\"data row1 col1\" >4.902524</td>\n",
       "      <td id=\"T_41e55_row1_col2\" class=\"data row1 col2\" >3.047541</td>\n",
       "      <td id=\"T_41e55_row1_col3\" class=\"data row1 col3\" >1.369357</td>\n",
       "      <td id=\"T_41e55_row1_col4\" class=\"data row1 col4\" >5.067812</td>\n",
       "      <td id=\"T_41e55_row1_col5\" class=\"data row1 col5\" >-1.940058</td>\n",
       "      <td id=\"T_41e55_row1_col6\" class=\"data row1 col6\" >-1.872742</td>\n",
       "      <td id=\"T_41e55_row1_col7\" class=\"data row1 col7\" >-1.255012</td>\n",
       "      <td id=\"T_41e55_row1_col8\" class=\"data row1 col8\" >0.413441</td>\n",
       "      <td id=\"T_41e55_row1_col9\" class=\"data row1 col9\" >0.862414</td>\n",
       "      <td id=\"T_41e55_row1_col10\" class=\"data row1 col10\" >0.562139</td>\n",
       "      <td id=\"T_41e55_row1_col11\" class=\"data row1 col11\" >0.781760</td>\n",
       "      <td id=\"T_41e55_row1_col12\" class=\"data row1 col12\" >-0.005957</td>\n",
       "      <td id=\"T_41e55_row1_col13\" class=\"data row1 col13\" >stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41e55_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_41e55_row2_col0\" class=\"data row2 col0\" >8.971707</td>\n",
       "      <td id=\"T_41e55_row2_col1\" class=\"data row2 col1\" >8.848428</td>\n",
       "      <td id=\"T_41e55_row2_col2\" class=\"data row2 col2\" >3.046479</td>\n",
       "      <td id=\"T_41e55_row2_col3\" class=\"data row2 col3\" >1.214518</td>\n",
       "      <td id=\"T_41e55_row2_col4\" class=\"data row2 col4\" >3.405158</td>\n",
       "      <td id=\"T_41e55_row2_col5\" class=\"data row2 col5\" >-1.207456</td>\n",
       "      <td id=\"T_41e55_row2_col6\" class=\"data row2 col6\" >-1.277210</td>\n",
       "      <td id=\"T_41e55_row2_col7\" class=\"data row2 col7\" >-0.920492</td>\n",
       "      <td id=\"T_41e55_row2_col8\" class=\"data row2 col8\" >0.163041</td>\n",
       "      <td id=\"T_41e55_row2_col9\" class=\"data row2 col9\" >0.766689</td>\n",
       "      <td id=\"T_41e55_row2_col10\" class=\"data row2 col10\" >0.839444</td>\n",
       "      <td id=\"T_41e55_row2_col11\" class=\"data row2 col11\" >0.109853</td>\n",
       "      <td id=\"T_41e55_row2_col12\" class=\"data row2 col12\" >0.003471</td>\n",
       "      <td id=\"T_41e55_row2_col13\" class=\"data row2 col13\" >unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41e55_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_41e55_row3_col0\" class=\"data row3 col0\" >0.716415</td>\n",
       "      <td id=\"T_41e55_row3_col1\" class=\"data row3 col1\" >7.669600</td>\n",
       "      <td id=\"T_41e55_row3_col2\" class=\"data row3 col2\" >4.486641</td>\n",
       "      <td id=\"T_41e55_row3_col3\" class=\"data row3 col3\" >2.340563</td>\n",
       "      <td id=\"T_41e55_row3_col4\" class=\"data row3 col4\" >3.963791</td>\n",
       "      <td id=\"T_41e55_row3_col5\" class=\"data row3 col5\" >-1.027473</td>\n",
       "      <td id=\"T_41e55_row3_col6\" class=\"data row3 col6\" >-1.938944</td>\n",
       "      <td id=\"T_41e55_row3_col7\" class=\"data row3 col7\" >-0.997374</td>\n",
       "      <td id=\"T_41e55_row3_col8\" class=\"data row3 col8\" >0.446209</td>\n",
       "      <td id=\"T_41e55_row3_col9\" class=\"data row3 col9\" >0.976744</td>\n",
       "      <td id=\"T_41e55_row3_col10\" class=\"data row3 col10\" >0.929381</td>\n",
       "      <td id=\"T_41e55_row3_col11\" class=\"data row3 col11\" >0.362718</td>\n",
       "      <td id=\"T_41e55_row3_col12\" class=\"data row3 col12\" >0.028871</td>\n",
       "      <td id=\"T_41e55_row3_col13\" class=\"data row3 col13\" >unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_41e55_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_41e55_row4_col0\" class=\"data row4 col0\" >3.134112</td>\n",
       "      <td id=\"T_41e55_row4_col1\" class=\"data row4 col1\" >7.608772</td>\n",
       "      <td id=\"T_41e55_row4_col2\" class=\"data row4 col2\" >4.943759</td>\n",
       "      <td id=\"T_41e55_row4_col3\" class=\"data row4 col3\" >9.857573</td>\n",
       "      <td id=\"T_41e55_row4_col4\" class=\"data row4 col4\" >3.525811</td>\n",
       "      <td id=\"T_41e55_row4_col5\" class=\"data row4 col5\" >-1.125531</td>\n",
       "      <td id=\"T_41e55_row4_col6\" class=\"data row4 col6\" >-1.845975</td>\n",
       "      <td id=\"T_41e55_row4_col7\" class=\"data row4 col7\" >-0.554305</td>\n",
       "      <td id=\"T_41e55_row4_col8\" class=\"data row4 col8\" >0.797110</td>\n",
       "      <td id=\"T_41e55_row4_col9\" class=\"data row4 col9\" >0.455450</td>\n",
       "      <td id=\"T_41e55_row4_col10\" class=\"data row4 col10\" >0.656947</td>\n",
       "      <td id=\"T_41e55_row4_col11\" class=\"data row4 col11\" >0.820923</td>\n",
       "      <td id=\"T_41e55_row4_col12\" class=\"data row4 col12\" >0.049860</td>\n",
       "      <td id=\"T_41e55_row4_col13\" class=\"data row4 col13\" >unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x27dfc598700>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Hsd.csv')\n",
    "df.head().style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93f8b057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6220ccbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tau1     0\n",
       "tau2     0\n",
       "tau3     0\n",
       "tau4     0\n",
       "p1       0\n",
       "p2       0\n",
       "p3       0\n",
       "p4       0\n",
       "g1       0\n",
       "g2       0\n",
       "g3       0\n",
       "g4       0\n",
       "stab     0\n",
       "stabf    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "852c1fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_92b13_row0_col0, #T_92b13_row0_col1, #T_92b13_row0_col2, #T_92b13_row0_col3, #T_92b13_row0_col4, #T_92b13_row0_col5, #T_92b13_row0_col6, #T_92b13_row0_col7, #T_92b13_row0_col8, #T_92b13_row0_col9, #T_92b13_row0_col10, #T_92b13_row0_col11, #T_92b13_row0_col12 {\n",
       "  background-color: #023858;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_92b13_row1_col0, #T_92b13_row1_col1, #T_92b13_row1_col2, #T_92b13_row1_col3, #T_92b13_row1_col4, #T_92b13_row1_col5, #T_92b13_row1_col6, #T_92b13_row1_col7, #T_92b13_row1_col8, #T_92b13_row1_col9, #T_92b13_row1_col10, #T_92b13_row1_col11, #T_92b13_row1_col12, #T_92b13_row2_col0, #T_92b13_row2_col1, #T_92b13_row2_col2, #T_92b13_row2_col3, #T_92b13_row2_col4, #T_92b13_row2_col5, #T_92b13_row2_col6, #T_92b13_row2_col7, #T_92b13_row2_col8, #T_92b13_row2_col9, #T_92b13_row2_col10, #T_92b13_row2_col11, #T_92b13_row2_col12, #T_92b13_row3_col0, #T_92b13_row3_col1, #T_92b13_row3_col2, #T_92b13_row3_col3, #T_92b13_row3_col4, #T_92b13_row3_col5, #T_92b13_row3_col6, #T_92b13_row3_col7, #T_92b13_row3_col8, #T_92b13_row3_col9, #T_92b13_row3_col10, #T_92b13_row3_col11, #T_92b13_row3_col12, #T_92b13_row4_col0, #T_92b13_row4_col1, #T_92b13_row4_col2, #T_92b13_row4_col3, #T_92b13_row4_col4, #T_92b13_row4_col5, #T_92b13_row4_col6, #T_92b13_row4_col7, #T_92b13_row4_col8, #T_92b13_row4_col9, #T_92b13_row4_col10, #T_92b13_row4_col11, #T_92b13_row4_col12, #T_92b13_row5_col0, #T_92b13_row5_col1, #T_92b13_row5_col2, #T_92b13_row5_col3, #T_92b13_row5_col4, #T_92b13_row5_col5, #T_92b13_row5_col6, #T_92b13_row5_col7, #T_92b13_row5_col8, #T_92b13_row5_col9, #T_92b13_row5_col10, #T_92b13_row5_col11, #T_92b13_row5_col12, #T_92b13_row6_col0, #T_92b13_row6_col1, #T_92b13_row6_col2, #T_92b13_row6_col3, #T_92b13_row6_col4, #T_92b13_row6_col5, #T_92b13_row6_col6, #T_92b13_row6_col7, #T_92b13_row6_col8, #T_92b13_row6_col9, #T_92b13_row6_col10, #T_92b13_row6_col11, #T_92b13_row6_col12, #T_92b13_row7_col0, #T_92b13_row7_col1, #T_92b13_row7_col2, #T_92b13_row7_col3, #T_92b13_row7_col4, #T_92b13_row7_col5, #T_92b13_row7_col6, #T_92b13_row7_col7, #T_92b13_row7_col8, #T_92b13_row7_col9, #T_92b13_row7_col10, #T_92b13_row7_col11, #T_92b13_row7_col12 {\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_92b13_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >tau1</th>\n",
       "      <th class=\"col_heading level0 col1\" >tau2</th>\n",
       "      <th class=\"col_heading level0 col2\" >tau3</th>\n",
       "      <th class=\"col_heading level0 col3\" >tau4</th>\n",
       "      <th class=\"col_heading level0 col4\" >p1</th>\n",
       "      <th class=\"col_heading level0 col5\" >p2</th>\n",
       "      <th class=\"col_heading level0 col6\" >p3</th>\n",
       "      <th class=\"col_heading level0 col7\" >p4</th>\n",
       "      <th class=\"col_heading level0 col8\" >g1</th>\n",
       "      <th class=\"col_heading level0 col9\" >g2</th>\n",
       "      <th class=\"col_heading level0 col10\" >g3</th>\n",
       "      <th class=\"col_heading level0 col11\" >g4</th>\n",
       "      <th class=\"col_heading level0 col12\" >stab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_92b13_level0_row0\" class=\"row_heading level0 row0\" >count</th>\n",
       "      <td id=\"T_92b13_row0_col0\" class=\"data row0 col0\" >10000.000000</td>\n",
       "      <td id=\"T_92b13_row0_col1\" class=\"data row0 col1\" >10000.000000</td>\n",
       "      <td id=\"T_92b13_row0_col2\" class=\"data row0 col2\" >10000.000000</td>\n",
       "      <td id=\"T_92b13_row0_col3\" class=\"data row0 col3\" >10000.000000</td>\n",
       "      <td id=\"T_92b13_row0_col4\" class=\"data row0 col4\" >10000.000000</td>\n",
       "      <td id=\"T_92b13_row0_col5\" class=\"data row0 col5\" >10000.000000</td>\n",
       "      <td id=\"T_92b13_row0_col6\" class=\"data row0 col6\" >10000.000000</td>\n",
       "      <td id=\"T_92b13_row0_col7\" class=\"data row0 col7\" >10000.000000</td>\n",
       "      <td id=\"T_92b13_row0_col8\" class=\"data row0 col8\" >10000.000000</td>\n",
       "      <td id=\"T_92b13_row0_col9\" class=\"data row0 col9\" >10000.000000</td>\n",
       "      <td id=\"T_92b13_row0_col10\" class=\"data row0 col10\" >10000.000000</td>\n",
       "      <td id=\"T_92b13_row0_col11\" class=\"data row0 col11\" >10000.000000</td>\n",
       "      <td id=\"T_92b13_row0_col12\" class=\"data row0 col12\" >10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92b13_level0_row1\" class=\"row_heading level0 row1\" >mean</th>\n",
       "      <td id=\"T_92b13_row1_col0\" class=\"data row1 col0\" >5.250000</td>\n",
       "      <td id=\"T_92b13_row1_col1\" class=\"data row1 col1\" >5.250001</td>\n",
       "      <td id=\"T_92b13_row1_col2\" class=\"data row1 col2\" >5.250004</td>\n",
       "      <td id=\"T_92b13_row1_col3\" class=\"data row1 col3\" >5.249997</td>\n",
       "      <td id=\"T_92b13_row1_col4\" class=\"data row1 col4\" >3.750000</td>\n",
       "      <td id=\"T_92b13_row1_col5\" class=\"data row1 col5\" >-1.250000</td>\n",
       "      <td id=\"T_92b13_row1_col6\" class=\"data row1 col6\" >-1.250000</td>\n",
       "      <td id=\"T_92b13_row1_col7\" class=\"data row1 col7\" >-1.250000</td>\n",
       "      <td id=\"T_92b13_row1_col8\" class=\"data row1 col8\" >0.525000</td>\n",
       "      <td id=\"T_92b13_row1_col9\" class=\"data row1 col9\" >0.525000</td>\n",
       "      <td id=\"T_92b13_row1_col10\" class=\"data row1 col10\" >0.525000</td>\n",
       "      <td id=\"T_92b13_row1_col11\" class=\"data row1 col11\" >0.525000</td>\n",
       "      <td id=\"T_92b13_row1_col12\" class=\"data row1 col12\" >0.015731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92b13_level0_row2\" class=\"row_heading level0 row2\" >std</th>\n",
       "      <td id=\"T_92b13_row2_col0\" class=\"data row2 col0\" >2.742548</td>\n",
       "      <td id=\"T_92b13_row2_col1\" class=\"data row2 col1\" >2.742549</td>\n",
       "      <td id=\"T_92b13_row2_col2\" class=\"data row2 col2\" >2.742549</td>\n",
       "      <td id=\"T_92b13_row2_col3\" class=\"data row2 col3\" >2.742556</td>\n",
       "      <td id=\"T_92b13_row2_col4\" class=\"data row2 col4\" >0.752160</td>\n",
       "      <td id=\"T_92b13_row2_col5\" class=\"data row2 col5\" >0.433035</td>\n",
       "      <td id=\"T_92b13_row2_col6\" class=\"data row2 col6\" >0.433035</td>\n",
       "      <td id=\"T_92b13_row2_col7\" class=\"data row2 col7\" >0.433035</td>\n",
       "      <td id=\"T_92b13_row2_col8\" class=\"data row2 col8\" >0.274256</td>\n",
       "      <td id=\"T_92b13_row2_col9\" class=\"data row2 col9\" >0.274255</td>\n",
       "      <td id=\"T_92b13_row2_col10\" class=\"data row2 col10\" >0.274255</td>\n",
       "      <td id=\"T_92b13_row2_col11\" class=\"data row2 col11\" >0.274255</td>\n",
       "      <td id=\"T_92b13_row2_col12\" class=\"data row2 col12\" >0.036919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92b13_level0_row3\" class=\"row_heading level0 row3\" >min</th>\n",
       "      <td id=\"T_92b13_row3_col0\" class=\"data row3 col0\" >0.500793</td>\n",
       "      <td id=\"T_92b13_row3_col1\" class=\"data row3 col1\" >0.500141</td>\n",
       "      <td id=\"T_92b13_row3_col2\" class=\"data row3 col2\" >0.500788</td>\n",
       "      <td id=\"T_92b13_row3_col3\" class=\"data row3 col3\" >0.500473</td>\n",
       "      <td id=\"T_92b13_row3_col4\" class=\"data row3 col4\" >1.582590</td>\n",
       "      <td id=\"T_92b13_row3_col5\" class=\"data row3 col5\" >-1.999891</td>\n",
       "      <td id=\"T_92b13_row3_col6\" class=\"data row3 col6\" >-1.999945</td>\n",
       "      <td id=\"T_92b13_row3_col7\" class=\"data row3 col7\" >-1.999926</td>\n",
       "      <td id=\"T_92b13_row3_col8\" class=\"data row3 col8\" >0.050009</td>\n",
       "      <td id=\"T_92b13_row3_col9\" class=\"data row3 col9\" >0.050053</td>\n",
       "      <td id=\"T_92b13_row3_col10\" class=\"data row3 col10\" >0.050054</td>\n",
       "      <td id=\"T_92b13_row3_col11\" class=\"data row3 col11\" >0.050028</td>\n",
       "      <td id=\"T_92b13_row3_col12\" class=\"data row3 col12\" >-0.080760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92b13_level0_row4\" class=\"row_heading level0 row4\" >25%</th>\n",
       "      <td id=\"T_92b13_row4_col0\" class=\"data row4 col0\" >2.874892</td>\n",
       "      <td id=\"T_92b13_row4_col1\" class=\"data row4 col1\" >2.875140</td>\n",
       "      <td id=\"T_92b13_row4_col2\" class=\"data row4 col2\" >2.875522</td>\n",
       "      <td id=\"T_92b13_row4_col3\" class=\"data row4 col3\" >2.874950</td>\n",
       "      <td id=\"T_92b13_row4_col4\" class=\"data row4 col4\" >3.218300</td>\n",
       "      <td id=\"T_92b13_row4_col5\" class=\"data row4 col5\" >-1.624901</td>\n",
       "      <td id=\"T_92b13_row4_col6\" class=\"data row4 col6\" >-1.625025</td>\n",
       "      <td id=\"T_92b13_row4_col7\" class=\"data row4 col7\" >-1.624960</td>\n",
       "      <td id=\"T_92b13_row4_col8\" class=\"data row4 col8\" >0.287521</td>\n",
       "      <td id=\"T_92b13_row4_col9\" class=\"data row4 col9\" >0.287552</td>\n",
       "      <td id=\"T_92b13_row4_col10\" class=\"data row4 col10\" >0.287514</td>\n",
       "      <td id=\"T_92b13_row4_col11\" class=\"data row4 col11\" >0.287494</td>\n",
       "      <td id=\"T_92b13_row4_col12\" class=\"data row4 col12\" >-0.015557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92b13_level0_row5\" class=\"row_heading level0 row5\" >50%</th>\n",
       "      <td id=\"T_92b13_row5_col0\" class=\"data row5 col0\" >5.250004</td>\n",
       "      <td id=\"T_92b13_row5_col1\" class=\"data row5 col1\" >5.249981</td>\n",
       "      <td id=\"T_92b13_row5_col2\" class=\"data row5 col2\" >5.249979</td>\n",
       "      <td id=\"T_92b13_row5_col3\" class=\"data row5 col3\" >5.249734</td>\n",
       "      <td id=\"T_92b13_row5_col4\" class=\"data row5 col4\" >3.751025</td>\n",
       "      <td id=\"T_92b13_row5_col5\" class=\"data row5 col5\" >-1.249966</td>\n",
       "      <td id=\"T_92b13_row5_col6\" class=\"data row5 col6\" >-1.249974</td>\n",
       "      <td id=\"T_92b13_row5_col7\" class=\"data row5 col7\" >-1.250007</td>\n",
       "      <td id=\"T_92b13_row5_col8\" class=\"data row5 col8\" >0.525009</td>\n",
       "      <td id=\"T_92b13_row5_col9\" class=\"data row5 col9\" >0.525003</td>\n",
       "      <td id=\"T_92b13_row5_col10\" class=\"data row5 col10\" >0.525015</td>\n",
       "      <td id=\"T_92b13_row5_col11\" class=\"data row5 col11\" >0.525002</td>\n",
       "      <td id=\"T_92b13_row5_col12\" class=\"data row5 col12\" >0.017142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92b13_level0_row6\" class=\"row_heading level0 row6\" >75%</th>\n",
       "      <td id=\"T_92b13_row6_col0\" class=\"data row6 col0\" >7.624690</td>\n",
       "      <td id=\"T_92b13_row6_col1\" class=\"data row6 col1\" >7.624893</td>\n",
       "      <td id=\"T_92b13_row6_col2\" class=\"data row6 col2\" >7.624948</td>\n",
       "      <td id=\"T_92b13_row6_col3\" class=\"data row6 col3\" >7.624838</td>\n",
       "      <td id=\"T_92b13_row6_col4\" class=\"data row6 col4\" >4.282420</td>\n",
       "      <td id=\"T_92b13_row6_col5\" class=\"data row6 col5\" >-0.874977</td>\n",
       "      <td id=\"T_92b13_row6_col6\" class=\"data row6 col6\" >-0.875043</td>\n",
       "      <td id=\"T_92b13_row6_col7\" class=\"data row6 col7\" >-0.875065</td>\n",
       "      <td id=\"T_92b13_row6_col8\" class=\"data row6 col8\" >0.762435</td>\n",
       "      <td id=\"T_92b13_row6_col9\" class=\"data row6 col9\" >0.762490</td>\n",
       "      <td id=\"T_92b13_row6_col10\" class=\"data row6 col10\" >0.762440</td>\n",
       "      <td id=\"T_92b13_row6_col11\" class=\"data row6 col11\" >0.762433</td>\n",
       "      <td id=\"T_92b13_row6_col12\" class=\"data row6 col12\" >0.044878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_92b13_level0_row7\" class=\"row_heading level0 row7\" >max</th>\n",
       "      <td id=\"T_92b13_row7_col0\" class=\"data row7 col0\" >9.999469</td>\n",
       "      <td id=\"T_92b13_row7_col1\" class=\"data row7 col1\" >9.999837</td>\n",
       "      <td id=\"T_92b13_row7_col2\" class=\"data row7 col2\" >9.999450</td>\n",
       "      <td id=\"T_92b13_row7_col3\" class=\"data row7 col3\" >9.999443</td>\n",
       "      <td id=\"T_92b13_row7_col4\" class=\"data row7 col4\" >5.864418</td>\n",
       "      <td id=\"T_92b13_row7_col5\" class=\"data row7 col5\" >-0.500108</td>\n",
       "      <td id=\"T_92b13_row7_col6\" class=\"data row7 col6\" >-0.500072</td>\n",
       "      <td id=\"T_92b13_row7_col7\" class=\"data row7 col7\" >-0.500025</td>\n",
       "      <td id=\"T_92b13_row7_col8\" class=\"data row7 col8\" >0.999937</td>\n",
       "      <td id=\"T_92b13_row7_col9\" class=\"data row7 col9\" >0.999944</td>\n",
       "      <td id=\"T_92b13_row7_col10\" class=\"data row7 col10\" >0.999982</td>\n",
       "      <td id=\"T_92b13_row7_col11\" class=\"data row7 col11\" >0.999930</td>\n",
       "      <td id=\"T_92b13_row7_col12\" class=\"data row7 col12\" >0.109403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x27df9f13dc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "926feb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tau1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015586</td>\n",
       "      <td>-0.005970</td>\n",
       "      <td>-0.017265</td>\n",
       "      <td>0.027183</td>\n",
       "      <td>-0.015485</td>\n",
       "      <td>-0.015924</td>\n",
       "      <td>-0.015807</td>\n",
       "      <td>0.010521</td>\n",
       "      <td>0.015350</td>\n",
       "      <td>-0.001279</td>\n",
       "      <td>0.005494</td>\n",
       "      <td>0.275761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau2</th>\n",
       "      <td>0.015586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014273</td>\n",
       "      <td>-0.001965</td>\n",
       "      <td>-0.004769</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.007673</td>\n",
       "      <td>-0.005963</td>\n",
       "      <td>-0.001742</td>\n",
       "      <td>0.015383</td>\n",
       "      <td>0.016508</td>\n",
       "      <td>-0.011764</td>\n",
       "      <td>0.290975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau3</th>\n",
       "      <td>-0.005970</td>\n",
       "      <td>0.014273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>0.016953</td>\n",
       "      <td>-0.003134</td>\n",
       "      <td>-0.008780</td>\n",
       "      <td>-0.017531</td>\n",
       "      <td>-0.011605</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>0.014702</td>\n",
       "      <td>-0.011497</td>\n",
       "      <td>0.280700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau4</th>\n",
       "      <td>-0.017265</td>\n",
       "      <td>-0.001965</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003173</td>\n",
       "      <td>0.010553</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>-0.011211</td>\n",
       "      <td>-0.004149</td>\n",
       "      <td>0.008431</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>-0.000491</td>\n",
       "      <td>0.278576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p1</th>\n",
       "      <td>0.027183</td>\n",
       "      <td>-0.004769</td>\n",
       "      <td>0.016953</td>\n",
       "      <td>-0.003173</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.573157</td>\n",
       "      <td>-0.584554</td>\n",
       "      <td>-0.579239</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.015405</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>-0.015451</td>\n",
       "      <td>0.010278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p2</th>\n",
       "      <td>-0.015485</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>-0.003134</td>\n",
       "      <td>0.010553</td>\n",
       "      <td>-0.573157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>-0.006844</td>\n",
       "      <td>0.015603</td>\n",
       "      <td>-0.018032</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>0.019817</td>\n",
       "      <td>0.006255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p3</th>\n",
       "      <td>-0.015924</td>\n",
       "      <td>0.007673</td>\n",
       "      <td>-0.008780</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>-0.584554</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012953</td>\n",
       "      <td>-0.003219</td>\n",
       "      <td>-0.011575</td>\n",
       "      <td>-0.005897</td>\n",
       "      <td>-0.010485</td>\n",
       "      <td>-0.003321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p4</th>\n",
       "      <td>-0.015807</td>\n",
       "      <td>-0.005963</td>\n",
       "      <td>-0.017531</td>\n",
       "      <td>-0.011211</td>\n",
       "      <td>-0.579239</td>\n",
       "      <td>-0.006844</td>\n",
       "      <td>0.012953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013636</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>-0.003515</td>\n",
       "      <td>0.017505</td>\n",
       "      <td>-0.020786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g1</th>\n",
       "      <td>0.010521</td>\n",
       "      <td>-0.001742</td>\n",
       "      <td>-0.011605</td>\n",
       "      <td>-0.004149</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.015603</td>\n",
       "      <td>-0.003219</td>\n",
       "      <td>-0.013636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007559</td>\n",
       "      <td>-0.005836</td>\n",
       "      <td>0.012431</td>\n",
       "      <td>0.282774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g2</th>\n",
       "      <td>0.015350</td>\n",
       "      <td>0.015383</td>\n",
       "      <td>0.007671</td>\n",
       "      <td>0.008431</td>\n",
       "      <td>0.015405</td>\n",
       "      <td>-0.018032</td>\n",
       "      <td>-0.011575</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.007559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012809</td>\n",
       "      <td>-0.014909</td>\n",
       "      <td>0.293601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g3</th>\n",
       "      <td>-0.001279</td>\n",
       "      <td>0.016508</td>\n",
       "      <td>0.014702</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>-0.005897</td>\n",
       "      <td>-0.003515</td>\n",
       "      <td>-0.005836</td>\n",
       "      <td>-0.012809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.308235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g4</th>\n",
       "      <td>0.005494</td>\n",
       "      <td>-0.011764</td>\n",
       "      <td>-0.011497</td>\n",
       "      <td>-0.000491</td>\n",
       "      <td>-0.015451</td>\n",
       "      <td>0.019817</td>\n",
       "      <td>-0.010485</td>\n",
       "      <td>0.017505</td>\n",
       "      <td>0.012431</td>\n",
       "      <td>-0.014909</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.279214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stab</th>\n",
       "      <td>0.275761</td>\n",
       "      <td>0.290975</td>\n",
       "      <td>0.280700</td>\n",
       "      <td>0.278576</td>\n",
       "      <td>0.010278</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>-0.003321</td>\n",
       "      <td>-0.020786</td>\n",
       "      <td>0.282774</td>\n",
       "      <td>0.293601</td>\n",
       "      <td>0.308235</td>\n",
       "      <td>0.279214</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "tau1  1.000000  0.015586 -0.005970 -0.017265  0.027183 -0.015485 -0.015924   \n",
       "tau2  0.015586  1.000000  0.014273 -0.001965 -0.004769  0.006573  0.007673   \n",
       "tau3 -0.005970  0.014273  1.000000  0.004354  0.016953 -0.003134 -0.008780   \n",
       "tau4 -0.017265 -0.001965  0.004354  1.000000 -0.003173  0.010553  0.006169   \n",
       "p1    0.027183 -0.004769  0.016953 -0.003173  1.000000 -0.573157 -0.584554   \n",
       "p2   -0.015485  0.006573 -0.003134  0.010553 -0.573157  1.000000  0.002388   \n",
       "p3   -0.015924  0.007673 -0.008780  0.006169 -0.584554  0.002388  1.000000   \n",
       "p4   -0.015807 -0.005963 -0.017531 -0.011211 -0.579239 -0.006844  0.012953   \n",
       "g1    0.010521 -0.001742 -0.011605 -0.004149  0.000721  0.015603 -0.003219   \n",
       "g2    0.015350  0.015383  0.007671  0.008431  0.015405 -0.018032 -0.011575   \n",
       "g3   -0.001279  0.016508  0.014702  0.003260  0.001069  0.007555 -0.005897   \n",
       "g4    0.005494 -0.011764 -0.011497 -0.000491 -0.015451  0.019817 -0.010485   \n",
       "stab  0.275761  0.290975  0.280700  0.278576  0.010278  0.006255 -0.003321   \n",
       "\n",
       "            p4        g1        g2        g3        g4      stab  \n",
       "tau1 -0.015807  0.010521  0.015350 -0.001279  0.005494  0.275761  \n",
       "tau2 -0.005963 -0.001742  0.015383  0.016508 -0.011764  0.290975  \n",
       "tau3 -0.017531 -0.011605  0.007671  0.014702 -0.011497  0.280700  \n",
       "tau4 -0.011211 -0.004149  0.008431  0.003260 -0.000491  0.278576  \n",
       "p1   -0.579239  0.000721  0.015405  0.001069 -0.015451  0.010278  \n",
       "p2   -0.006844  0.015603 -0.018032  0.007555  0.019817  0.006255  \n",
       "p3    0.012953 -0.003219 -0.011575 -0.005897 -0.010485 -0.003321  \n",
       "p4    1.000000 -0.013636  0.002850 -0.003515  0.017505 -0.020786  \n",
       "g1   -0.013636  1.000000  0.007559 -0.005836  0.012431  0.282774  \n",
       "g2    0.002850  0.007559  1.000000 -0.012809 -0.014909  0.293601  \n",
       "g3   -0.003515 -0.005836 -0.012809  1.000000  0.006900  0.308235  \n",
       "g4    0.017505  0.012431 -0.014909  0.006900  1.000000  0.279214  \n",
       "stab -0.020786  0.282774  0.293601  0.308235  0.279214  1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "880cde43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat(cols):\n",
    "    if cols['stab'] <=0:\n",
    "        return 'stable'\n",
    "    else:\n",
    "        return 'unstable'\n",
    "df['stab'] = df.apply(stat,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d4d0afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['stabf'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66d9c55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unstable    0.638\n",
       "stable      0.362\n",
       "Name: stab, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stab'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1b5ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =df.drop('stab',axis=1)\n",
    "y =df['stab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d827b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b3effff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29df27e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4b2898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f69430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_train = scaler.fit_transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8177da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9580cc",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62517e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9455"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_encod = le.fit_transform(y_train)\n",
    "y_test_encod = le.transform(y_test)\n",
    "model = XGBClassifier()\n",
    "model.fit(X_scaled_train,y_train_encod)\n",
    "y_pred = model.predict(X_scaled_test)\n",
    "accuracy_score(y_test_encod,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1920f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model (model): \n",
    "    le = LabelEncoder()\n",
    "  \n",
    "    model = model\n",
    "    model.fit(X_scaled_train,y_train)\n",
    "    y_pred =model.predict(X_scaled_test)\n",
    "    \n",
    "    accuracy =accuracy_score(y_test,y_pred)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1debaa",
   "metadata": {},
   "source": [
    "### LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aee49ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9395"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(LGBMClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a4ebb1",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a07c19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9255"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6660db3",
   "metadata": {},
   "source": [
    "### ExtraTree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "998149a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.927"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(ExtraTreesClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4ed88d",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6c75622",
   "metadata": {},
   "outputs": [],
   "source": [
    "etr = ExtraTreesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48bfa6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on ExtraTreesClassifier in module sklearn.ensemble._forest object:\n",
      "\n",
      "class ExtraTreesClassifier(ForestClassifier)\n",
      " |  ExtraTreesClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=False, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
      " |  \n",
      " |  An extra-trees classifier.\n",
      " |  \n",
      " |  This class implements a meta estimator that fits a number of\n",
      " |  randomized decision trees (a.k.a. extra-trees) on various sub-samples\n",
      " |  of the dataset and uses averaging to improve the predictive accuracy\n",
      " |  and control over-fitting.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <forest>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_estimators : int, default=100\n",
      " |      The number of trees in the forest.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``n_estimators`` changed from 10 to 100\n",
      " |         in 0.22.\n",
      " |  \n",
      " |  criterion : {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      \"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the\n",
      " |      Shannon information gain, see :ref:`tree_mathematical_formulation`.\n",
      " |      Note: This parameter is tree-specific.\n",
      " |  \n",
      " |  max_depth : int, default=None\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : {\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\"\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `max(1, int(max_features * n_features_in_))` features are considered at each\n",
      " |        split.\n",
      " |      - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      .. versionchanged:: 1.1\n",
      " |          The default of `max_features` changed from `\"auto\"` to `\"sqrt\"`.\n",
      " |  \n",
      " |      .. deprecated:: 1.1\n",
      " |          The `\"auto\"` option was deprecated in 1.1 and will be removed\n",
      " |          in 1.3.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  bootstrap : bool, default=False\n",
      " |      Whether bootstrap samples are used when building trees. If False, the\n",
      " |      whole dataset is used to build each tree.\n",
      " |  \n",
      " |  oob_score : bool, default=False\n",
      " |      Whether to use out-of-bag samples to estimate the generalization score.\n",
      " |      Only available if bootstrap=True.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
      " |      :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
      " |      trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors. See :term:`Glossary\n",
      " |      <n_jobs>` for more details.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls 3 sources of randomness:\n",
      " |  \n",
      " |      - the bootstrapping of the samples used when building trees\n",
      " |        (if ``bootstrap=True``)\n",
      " |      - the sampling of the features to consider when looking for the best\n",
      " |        split at each node (if ``max_features < n_features``)\n",
      " |      - the draw of the splits for each of the `max_features`\n",
      " |  \n",
      " |      See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Controls the verbosity when fitting and predicting.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
      " |      new forest. See :term:`Glossary <warm_start>` and\n",
      " |      :ref:`gradient_boosting_warm_start` for details.\n",
      " |  \n",
      " |  class_weight : {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one. For\n",
      " |      multi-output problems, a list of dicts can be provided in the same\n",
      " |      order as the columns of y.\n",
      " |  \n",
      " |      Note that for multioutput (including multilabel) weights should be\n",
      " |      defined for each class of every column in its own dict. For example,\n",
      " |      for four-class multilabel classification weights should be\n",
      " |      [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      " |      [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |      The \"balanced_subsample\" mode is the same as \"balanced\" except that\n",
      " |      weights are computed based on the bootstrap sample for every tree\n",
      " |      grown.\n",
      " |  \n",
      " |      For multi-output, the weights of each column of y will be multiplied.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  max_samples : int or float, default=None\n",
      " |      If bootstrap is True, the number of samples to draw from X\n",
      " |      to train each base estimator.\n",
      " |  \n",
      " |      - If None (default), then draw `X.shape[0]` samples.\n",
      " |      - If int, then draw `max_samples` samples.\n",
      " |      - If float, then draw `max_samples * X.shape[0]` samples. Thus,\n",
      " |        `max_samples` should be in the interval `(0.0, 1.0]`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  estimator_ : :class:`~sklearn.tree.ExtraTreesClassifier`\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |      .. versionadded:: 1.2\n",
      " |         `base_estimator_` was renamed to `estimator_`.\n",
      " |  \n",
      " |  base_estimator_ : ExtraTreesClassifier\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |      .. deprecated:: 1.2\n",
      " |          `base_estimator_` is deprecated and will be removed in 1.4.\n",
      " |          Use `estimator_` instead.\n",
      " |  \n",
      " |  estimators_ : list of DecisionTreeClassifier\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,) or a list of such arrays\n",
      " |      The classes labels (single output problem), or a list of arrays of\n",
      " |      class labels (multi-output problem).\n",
      " |  \n",
      " |  n_classes_ : int or list\n",
      " |      The number of classes (single output problem), or a list containing the\n",
      " |      number of classes for each output (multi-output problem).\n",
      " |  \n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The impurity-based feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  oob_decision_function_ : ndarray of shape (n_samples, n_classes) or             (n_samples, n_classes, n_outputs)\n",
      " |      Decision function computed with out-of-bag estimate on the training\n",
      " |      set. If n_estimators is small it might be possible that a data point\n",
      " |      was never left out during the bootstrap. In this case,\n",
      " |      `oob_decision_function_` might contain NaN. This attribute exists\n",
      " |      only when ``oob_score`` is True.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  ExtraTreesRegressor : An extra-trees regressor with random splits.\n",
      " |  RandomForestClassifier : A random forest classifier with optimal splits.\n",
      " |  RandomForestRegressor : Ensemble regressor using trees with optimal splits.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized\n",
      " |         trees\", Machine Learning, 63(1), 3-42, 2006.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.ensemble import ExtraTreesClassifier\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> X, y = make_classification(n_features=4, random_state=0)\n",
      " |  >>> clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
      " |  >>> clf.fit(X, y)\n",
      " |  ExtraTreesClassifier(random_state=0)\n",
      " |  >>> clf.predict([[0, 0, 0, 0]])\n",
      " |  array([1])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ExtraTreesClassifier\n",
      " |      ForestClassifier\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      BaseForest\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=False, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ForestClassifier:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class for X.\n",
      " |      \n",
      " |      The predicted class of an input sample is a vote by the trees in\n",
      " |      the forest, weighted by their probability estimates. That is,\n",
      " |      the predicted class is the one with highest mean probability\n",
      " |      estimate across the trees.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities for X.\n",
      " |      \n",
      " |      The predicted class log-probabilities of an input sample is computed as\n",
      " |      the log of the mean predicted class probabilities of the trees in the\n",
      " |      forest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes), or a list of such arrays\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      The predicted class probabilities of an input sample are computed as\n",
      " |      the mean predicted class probabilities of the trees in the forest.\n",
      " |      The class probability of a single tree is the fraction of samples of\n",
      " |      the same class in a leaf.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes), or a list of such arrays\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseForest:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the forest to X, return leaf indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : ndarray of shape (n_samples, n_estimators)\n",
      " |          For each datapoint x in X and for each tree in the forest,\n",
      " |          return the index of the leaf x ends up in.\n",
      " |  \n",
      " |  decision_path(self, X)\n",
      " |      Return the decision path in the forest.\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
      " |          Return a node indicator matrix where non zero elements indicates\n",
      " |          that the samples goes through the nodes. The matrix is of CSR\n",
      " |          format.\n",
      " |      \n",
      " |      n_nodes_ptr : ndarray of shape (n_estimators + 1,)\n",
      " |          The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]\n",
      " |          gives the indicator value for the i-th estimator.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a forest of trees from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, its dtype will be converted\n",
      " |          to ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseForest:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      The impurity-based feature importances.\n",
      " |      \n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          The values of this array sum to 1, unless all trees are single node\n",
      " |          trees consisting of only the root node, in which case it will be an\n",
      " |          array of zeros.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  base_estimator_\n",
      " |      Estimator used to grow the ensemble.\n",
      " |  \n",
      " |  estimator_\n",
      " |      Estimator used to grow the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ExtraTreesClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f76e9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribution ={\"n_estimators\":[64,100,150,200,300,500],\n",
    "                    'max_features':['sqrt','log2',None,'auto'],\n",
    "                    'min_samples_split':[1,2,3,4,5,6,7,8,9],\n",
    "                    'min_samples_leaf':[1,2,3,4,5,6,7,8,9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5186be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_model = RandomizedSearchCV(estimator=etr,param_distributions=param_distribution,\n",
    "                                  cv=10,n_iter=10,n_jobs=-1,scoring='accuracy',verbose=1,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e54b62ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10, estimator=ExtraTreesClassifier(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None,\n",
       "                                                         &#x27;auto&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9],\n",
       "                                        &#x27;min_samples_split&#x27;: [1, 2, 3, 4, 5, 6,\n",
       "                                                              7, 8, 9],\n",
       "                                        &#x27;n_estimators&#x27;: [64, 100, 150, 200, 300,\n",
       "                                                         500]},\n",
       "                   random_state=1, scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10, estimator=ExtraTreesClassifier(), n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None,\n",
       "                                                         &#x27;auto&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9],\n",
       "                                        &#x27;min_samples_split&#x27;: [1, 2, 3, 4, 5, 6,\n",
       "                                                              7, 8, 9],\n",
       "                                        &#x27;n_estimators&#x27;: [64, 100, 150, 200, 300,\n",
       "                                                         500]},\n",
       "                   random_state=1, scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=ExtraTreesClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'max_features': ['sqrt', 'log2', None,\n",
       "                                                         'auto'],\n",
       "                                        'min_samples_leaf': [1, 2, 3, 4, 5, 6,\n",
       "                                                             7, 8, 9],\n",
       "                                        'min_samples_split': [1, 2, 3, 4, 5, 6,\n",
       "                                                              7, 8, 9],\n",
       "                                        'n_estimators': [64, 100, 150, 200, 300,\n",
       "                                                         500]},\n",
       "                   random_state=1, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_model.fit(X_scaled_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21cb3753",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model =random_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9add102e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesClassifier(max_features=None, min_samples_leaf=2, min_samples_split=6,\n",
       "                     n_estimators=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(max_features=None, min_samples_leaf=2, min_samples_split=6,\n",
       "                     n_estimators=500)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesClassifier(max_features=None, min_samples_leaf=2, min_samples_split=6,\n",
       "                     n_estimators=500)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "facb26ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9345"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd36b9e",
   "metadata": {},
   "source": [
    "The accuracy of our new optimal model was higher. Since it moved from 0.927 to 0.935"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6322f9",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23b61fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12929314, 0.13123506, 0.12672113, 0.12830687, 0.01286634,\n",
       "       0.01514669, 0.01529447, 0.0144875 , 0.10164368, 0.10700382,\n",
       "       0.10986452, 0.10813679])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d187e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tau1', 'tau2', 'tau3', 'tau4', 'p1', 'p2', 'p3', 'p4', 'g1', 'g2',\n",
       "       'g3', 'g4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eca642de",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame({'features':X_train.columns,\n",
    "                                     'coefficient':best_model.feature_importances_}).sort_values('coefficient').set_index('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec948d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p1</th>\n",
       "      <td>0.012866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p4</th>\n",
       "      <td>0.014487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p2</th>\n",
       "      <td>0.015147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p3</th>\n",
       "      <td>0.015294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g1</th>\n",
       "      <td>0.101644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g2</th>\n",
       "      <td>0.107004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g4</th>\n",
       "      <td>0.108137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g3</th>\n",
       "      <td>0.109865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau3</th>\n",
       "      <td>0.126721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau4</th>\n",
       "      <td>0.128307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau1</th>\n",
       "      <td>0.129293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau2</th>\n",
       "      <td>0.131235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          coefficient\n",
       "features             \n",
       "p1           0.012866\n",
       "p4           0.014487\n",
       "p2           0.015147\n",
       "p3           0.015294\n",
       "g1           0.101644\n",
       "g2           0.107004\n",
       "g4           0.108137\n",
       "g3           0.109865\n",
       "tau3         0.126721\n",
       "tau4         0.128307\n",
       "tau1         0.129293\n",
       "tau2         0.131235"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a144e3",
   "metadata": {},
   "source": [
    "We can see that p1 is the least important feature while tau2 is the most important feature"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
